# -*- coding: utf-8 -*-
"""cnn_921.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S3pWssMlycDnj-RNsXkweJ_iHLD-cn6j
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.applications import MobileNet, Xception, ResNet50, InceptionV3
from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from google.colab import drive   

drive.mount('/content/gdrive/')

# 파일 다운로드

import shutil

shutil.copy('/content/gdrive/My Drive/blood/blood_new.zip', '/content/')

root_dir = '/content'

import os
import shutil

if os.path.exists( os.path.join(root_dir, 'blood_new') ):
    shutil.rmtree( os.path.join(root_dir, 'blood_new') )

import zipfile

with zipfile.ZipFile(os.path.join(root_dir, 'blood_new.zip'), 'r') as target_file:

    target_file.extractall(os.path.join(root_dir, 'blood_new'))

import os
import shutil

if not os.path.exists(os.path.join(root_dir, 'blood_new/test')):    
    os.mkdir(os.path.join(root_dir, 'blood_new/test'))

if not os.path.exists(os.path.join(root_dir, 'blood_new/test_image_files')):    
    os.mkdir(os.path.join(root_dir, 'blood_new/test_image_files'))

import os
import glob

label_name_list = os.listdir(os.path.join(root_dir, '/content/blood_new/blood_new/train'))

print('total label nums = ', len(label_name_list))
print('=================================================')
print(label_name_list)

import os
import glob
import shutil

ratio = 0.2    # train : test = 80 : 20

src_root_dir = os.path.join(root_dir,'/content/blood_new/blood_new/train/')
dst_root_dir = os.path.join(root_dir, '/content/blood_new/test/')
label_name_list = os.listdir(src_root_dir) 

for label_name in label_name_list:   # test 디렉토리에 label 디렉토리 생성
    dst_label_name_dir = dst_root_dir + label_name

    if not os.path.exists(dst_label_name_dir):
        os.mkdir(dst_label_name_dir)

for label_name in label_name_list:    # 파일 move src dir => dst dir
    train_image_file_list = glob.glob(src_root_dir+label_name+'/*')
    split_num = int(ratio*len(train_image_file_list))
    test_image_file_list = train_image_file_list[0:split_num]

    for image_file in test_image_file_list:
        shutil.move(image_file, dst_root_dir+label_name)    # move

# train : test 데이터 비율 확인

src_root_dir = os.path.join(root_dir, '/content/blood_new/blood_new/train/')
dst_root_dir = os.path.join(root_dir, '/content/blood_new/test/')

train_label_name_list = os.listdir(src_root_dir)
test_label_name_list = os.listdir(src_root_dir)

train_label_name_list.sort()
test_label_name_list.sort()

if train_label_name_list != test_label_name_list:
    print('fatal error !!!!')
else:
    print(len(train_label_name_list), len(test_label_name_list))

# 데이터 개수 확인

for label_name in train_label_name_list:

    train_data_nums = len(os.listdir(src_root_dir+label_name))
    test_data_nums = len(os.listdir(dst_root_dir+label_name))

    print('train => ', label_name, train_data_nums, ' , test => ', label_name, test_data_nums)
    print('=======================================================')

import os
import glob
import shutil

src_root_dir = os.path.join(root_dir, '/content/blood_new/test/')
dst_root_dir = os.path.join(root_dir, '/content/blood_new/test_image_files')

label_name_list = os.listdir(src_root_dir)

for label_name in label_name_list:  # 파일 copy src dir => dst dir
    image_file_list = glob.glob(src_root_dir+label_name+'/*')
    print('total [%s] image file nums => [%s]' % (label_name ,len(image_file_list)))

    copy_nums = 0

    for image_file in image_file_list:
        shutil.copy(image_file, dst_root_dir)    # copy 
        copy_nums = copy_nums + 1

    print('total copy nums => ', copy_nums)

IMG_WIDTH = 224  
IMG_HEIGHT = 224  

train_dir = os.path.join(root_dir, '/content/blood_new/blood_new/train/')
validation_dir = os.path.join(root_dir, '/content/blood_new/blood_new/train/')
test_dir = os.path.join(root_dir, '/content/blood_new/test/')

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,
                                    height_shift_range=0.1, shear_range=0.1, zoom_range=[0.5, 4.0],
                                    validation_split=0.15)

validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.15)

train_generator = train_datagen.flow_from_directory(train_dir, batch_size=32, color_mode='rgb', 
                                                class_mode='sparse', subset = 'training',
                                                target_size=(IMG_WIDTH,IMG_HEIGHT))

validation_generator = validation_datagen.flow_from_directory(validation_dir, batch_size=32, color_mode='rgb', 
                                                          class_mode='sparse', subset = 'validation',
                                                          target_size=(IMG_WIDTH,IMG_HEIGHT))

print(train_generator.class_indices)

model = Sequential()
model.add(Conv2D(32, kernel_size = (3, 3), 
                 padding = 'same',
                 activation = 'relu',
                 input_shape = (224, 224, 3)))
model.add(Conv2D(64, (3, 3), 
                 padding = 'same',
                 activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2, 2)))
model.add(Flatten())
model.add(Dense(128, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(2e-5), metrics=['accuracy'])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

earlystopping = EarlyStopping(monitor='val_loss', patience=5)                     

hist = model.fit(train_generator, validation_data=validation_generator,
                 epochs=50, callbacks=[earlystopping])

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'], label='train')
plt.plot(hist.history['val_accuracy'], label='validation')
plt.title('Accuracy Trend')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(loc='best')

plt.grid()
plt.show()

plt.plot(hist.history['loss'], label='train')
plt.plot(hist.history['val_loss'], label='validation')
plt.title('Loss Trend')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(loc='best')
plt.grid()
plt.show()

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(test_dir, batch_size=32, color_mode='rgb',
                                              class_mode='sparse', target_size=(IMG_WIDTH,IMG_HEIGHT))

model.evaluate(test_generator)

import random
import os
import numpy as np
import cv2
import glob

label_dict = {'Castoff': 0, 'impact': 1, 'swing': 2}
#test_image_files_list = []
#[test_image_files_list.append(file) for file in glob.glob('/content/blood_new/test_image_files/*')]
test_image_files_list = glob.glob('/content/blood_new/test_image_files/*')
#test_image_files_list = glob.glob('/content/blood_new/test_image_files/*')
#for path in test_image_files_list:
    #print(path)
#test_image_files_list = glob.glob('/content/blood_new/test_image_files/*')

print('hi: ',test_image_files_list)

#random.shuffle(test_image_files_list)

test_num = 54
test_image_files = test_image_files_list[:test_num]  # 태스트 파일이름은 정답.숫자.jpg 

label_list = []

for i in range(len(test_image_files)):
    label = test_image_files[i].split('/')[-1].split('.')[0].strip()
    label_list.append(label_dict[label])

src_img_list = []

for i in range(len(test_image_files)):
    src_img = cv2.imread(test_image_files[i], cv2.IMREAD_COLOR)
    src_img = cv2.resize(src_img, dsize=(IMG_WIDTH, IMG_HEIGHT))
    src_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)
    src_img = src_img / 255.0

    src_img_list.append(src_img)

# 4차원 텐서  변환
src_img_array = np.array(src_img_list)
label_array = np.array(label_list)

print(src_img_array.shape, label_array.shape)
print(label_array)

pred = model.predict(src_img_array)
print(pred.shape)

import matplotlib.pyplot as plt

class_names = ['Castoff', 'impact', 'swing',]

plt.figure(figsize=(24,24))

for pos in range(len(pred)):

    plt.subplot(9,6,pos+1)
    plt.axis('off')

    label_str = class_names[label_array[pos]]
    pred_str = class_names[np.argmax(pred[pos])]

    plt.title('label:' + label_str + '\npred:' + pred_str)

    plt.imshow(src_img_array[pos])

plt.tight_layout()
#plt.show()
plt.savefig('tight_layout.eps', format='eps')

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'], label='test')
plt.plot(hist.history['val_accuracy'], label='validation')
plt.title('Accuracy Trend')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(loc='best')
plt.grid()
plt.show()

print(hist.history['accuracy'])

plt.plot(hist.history['val_loss'], color='b', label="validation loss")
plt.title("Test Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.plot(hist.history['accuracy'], color='b', label="accuracy")
plt.title("accuracy")
plt.xlabel("Number of Epochs")
plt.ylabel("accuracy")
plt.legend()
plt.show()

prediction = []
for x in pred:

  prediction.append(np.argmax(x))

print(len(prediction))
print(len(label_array))

#from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
#from sklearn.metrics import accuracy_score

# confusion matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt


class_names = ['Castoff', 'impact', 'swing',] # 라벨 설정

cm = confusion_matrix(label_array,prediction)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=class_names)

disp = disp.plot(include_values=True,
                 xticks_rotation='horizontal')

plt.show()